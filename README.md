# JAX_HandsOn

In this repo I created an MLP (multi-layer perceptron) and trained it as a classifier on MNIST (although it's trivial to use a more complex dataset) - all this in pure JAX (no Flax/Haiku/Optax).

I then added visualizations such as:
Visualizing MLP's learned weights
Visualizing embeddings of a batch of images in t-SNE
Finally, analyzed the dead neurons

Credit: 
Got the inspiration from the official advanced JAX tutorial here: 
https://docs.jax.dev/en/latest/notebooks/Neural_Network_and_Data_Loading.html
